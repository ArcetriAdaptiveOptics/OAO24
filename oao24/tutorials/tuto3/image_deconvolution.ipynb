{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 3  - Deconvolution\n",
    "\n",
    "Authors:\n",
    "Romain JL Fétick, Alexis Lau\n",
    "\n",
    "This notebook is designed to run in either Google Colab, or locally in your machine (need to install packages). \n",
    "\n",
    "#### **Table of contents**\n",
    "This tutorial will cover the following topics: \n",
    "1. Image formation\n",
    "2. Wiener filtering \n",
    "3. MAP deconvolution\n",
    "\n",
    "#### **Introduction**\n",
    "Deconvolution is cruciaal for enhancing image quality by reversing the effects of distortion and blurring, which often occur due to factors like system limitations, atmospheric turbulence, motion blur, or optical imperfections. In real-world scenarios, the captured image may not accurately represent the true object, but deconvolution helps restore a clearer and more precise version of the original image.\n",
    "\n",
    "In astrophysics, deconvolution plays a key role in extracting valuable information from images of celestial objects. It aims to restore the high spatial frequencies lost due to distortions, allowing for more detailed analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.ndimage.filters import convolve, convolve1d, gaussian_filter\n",
    "import math\n",
    "from scipy import fftpack\n",
    "import sys\n",
    "\n",
    "from scipy.signal import fftconvolve\n",
    "from numpy.fft import fft2, fftshift, ifft2, ifftshift\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By installing the oao24, you will have access to the data for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ArcetriAdaptiveOptics/OAO24.git\n",
    "from oao24 import package_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Deconvolution\n",
    "1. Create an image with objects and PSFs provided\n",
    "   1. Objects: Vesta, Ganymede (to be determined) \n",
    "   2. PSFs: Papyrus-liked PSFs \n",
    "2. Using Wiener Filtering to deconvolve an image \n",
    "   1. Equations for the noise estimation will be provided in the notebook \n",
    "3. MAP \n",
    "   1. Try to build your own MAP -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1 - Image formation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting work on deconvolution, it is essential to first understand how an image is formed. Assuming the noise is purely additive, any 2D image can be characterised by its intensity distribution $I$: \n",
    "\n",
    "\\begin{equation}\n",
    "I = H * O + N\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "where $I$ is the image, $H$ is the Point Spread Function (PSF), $O$ is the object, and $N$ represents the additive noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions to carry out certain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft(tab):\n",
    "    \"\"\"Centered FFT\"\"\"\n",
    "    return fftshift(fft2(fftshift(tab)))\n",
    "\n",
    "def ifft_real(tab):\n",
    "    \"\"\"Centered iFFT, force result to be real\"\"\"\n",
    "    return np.real(ifftshift(ifft2(ifftshift(tab))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in doubt, you can always use ? to find out how the function works. Below is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter to modify\n",
    "flux = 4e7\n",
    "ron = 4\n",
    "photon_noise = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will load the files to create the image. The PSF and the object are loaded into .fits format, which would require astropy to open it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = fits.open(os.path.join(package_data.tuto3_folder(),'psf_high_sr.fits'))\n",
    "psf = fts[0].data\n",
    "fts.close()\n",
    "\n",
    "fts = fits.open(os.path.join(package_data.tuto3_folder(), 'vesta.fits'))\n",
    "vesta = fts[0].data\n",
    "fts.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an image with a given flux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vesta = flux*vesta/np.sum(vesta)\n",
    "\n",
    "nx = vesta.shape[0]\n",
    "\n",
    "noise_ron = ron*np.random.randn(nx,nx) # Gaussian noise \n",
    "convolution = ifft_real(fft(vesta)*fft(psf))\n",
    "\n",
    "if photon_noise:\n",
    "    image = np.random.poisson(convolution) + noise_ron\n",
    "else:\n",
    "    image = convolution + noise_ron\n",
    "\n",
    "\n",
    "# Plot the image\n",
    "fig, axes = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "axes[0].set_title('Object')\n",
    "axes[0].imshow(vesta,cmap='gray')\n",
    "\n",
    "axes[1].set_title('PSF')\n",
    "axes[1].imshow(np.log(psf) ,cmap='gray')\n",
    "\n",
    "axes[2].set_title('Image')\n",
    "axes[2].imshow(image,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: How does the image look like when we only have gaussian noise? Try setting the photon_noise = False to find out. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2 - Wiener filtering**\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{w}_k = \\frac{\\hat{h}_k^*}{|\\hat{h}_k|^2 + \\frac{E\\{| \\hat{n}_k |^2\\}}{E\\{| \\hat{x}_k |^2\\}}}\n",
    "$$\n",
    "\n",
    "\n",
    "This equation represents the Wiener filtering process in a communication or signal processing context, where the goal is to estimate the original signal $\\hat{x}_{W,k}$ from a noisy observation $ \\hat{y}  $. Here's a breakdown of the components:\n",
    "\n",
    "Equation Breakdown:\n",
    "\n",
    "- $\\hat{w}_k$ represents the **Wiener filter** at frequency index \\(k\\), which is a function of the signal and noise power spectra. This coefficient is applied to the noisy observation $\\hat{y}$ to produce the filtered estimate.\n",
    "\n",
    "- $ \\hat{h}_k $ represents the Fourier transform of the PSF (**OTF**) at index \\(k\\). \n",
    "\n",
    "- $ \\hat{n}_k $ represents the Fourier transform of **noise** in the system at frequency index \\(k\\), with $ E\\left\\{ |\\hat{n}_k|^2 \\right\\} $ being its expected power.\n",
    "\n",
    "- $ \\hat{x}_k $ is the Fourier transform of **original signal** at frequency index \\(k\\), and $ E\\left\\{ |\\hat{x}_k|^2 \\right\\} $ represents its expected power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have an image which includes the noise and PSF. It's time to start thinking about how to deblur the image. Wiener filtering makes assumption about the noise (Gaussian, stationary) while astronomical images often dominated by photon noise. Also, we need model to estimate the PSD of both the object and the noise. \n",
    "\n",
    "**Task**: From the equation above, try to build wiener filter function.\n",
    "\n",
    "*Hint*: you need to estimate the noise of the image, and a PSD model as a prior for the wiener filtering. Below there are some helper functions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_noise_std(image, psf):\n",
    "    \"\"\"Estimate the noise standard deviation of an image\"\"\"\n",
    "    image_tf = fft(image)\n",
    "    mtf = np.abs(fft(psf))\n",
    "    msk_outside = mtf < 1e-6\n",
    "    noise_var = np.mean(np.abs(image_tf[msk_outside])**2) / nx**2\n",
    "    return np.sqrt(noise_var)\n",
    "\n",
    "def estimate_ron(image, psf, photon_noise=False):\n",
    "    \"\"\"Estimate the RON from an image\"\"\"\n",
    "    noise_var = estimate_noise_std(image, psf)**2\n",
    "    photon_var = min(np.mean(image), noise_var) # min() avoid issue in sqrt\n",
    "    ron_std = np.sqrt(noise_var - photon_noise*photon_var)\n",
    "    return ron_std\n",
    "\n",
    "def psd_model(nx, flux, pix_size):\n",
    "    \"\"\"\n",
    "    Model of an object PSD as:\n",
    "        PSF(f) = flux²/(1+(f/f_cut)^3)\n",
    "    \"\"\"\n",
    "    xx,yy = np.mgrid[0:nx,0:nx] - nx//2\n",
    "    rr = np.sqrt(xx**2+yy**2)\n",
    "    rho = nx/pix_size/2\n",
    "    return flux**2/(1+(rr/rho)**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier transforms of various input for data analysis later\n",
    "otf = fftshift(fft2(fftshift(psf)))\n",
    "ft_image = fftshift(fft2(fftshift(image)))\n",
    "ft_vesta = fftshift(fft2(fftshift(vesta)))\n",
    "ft_noise = fftshift(fft2(fftshift(noise_ron)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your results here!\n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].set_title('Object')\n",
    "ax[0].imshow(vesta, cmap='gray')\n",
    "\n",
    "ax[1].set_title('Image')\n",
    "ax[1].imshow(image, cmap='gray')\n",
    "\n",
    "ax[2].set_title('Wiener filtering')\n",
    "ax[2].imshow(deconv_wiener, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3 - Maximum A Posteriori**\n",
    "The Maximum A Posteriori (MAP) is used to restore an image or signal that has been degraded by blurring and noise. MAP is rooted in Bayesian estimation and provides a probabilistic framework to recover the original image by maximizing the posterior probability.\n",
    "\n",
    "\n",
    "MAP aims to estimate the most likely original object (or image) $O$ given the observed image $I$, based on prior knowledge about the image and the noise. It seeks the estimate object that maximizes the posterior probability:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{\\text{MAP}} = \\arg\\min_{\\mathbf{x}} \\left\\{ \\frac{1}{2} \\| \\mathbf{y} - H \\mathbf{x} \\|_{C_n^{-1}}^2 - \\log P(\\mathbf{x}) \\right\\}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Task** (See in the `__call__ `in the class `MAPcriterion`): \n",
    "- Code your own function for the map criterion \n",
    "- Code the associated gradient function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions for building the MAP criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(image, obj, psf, weights):\n",
    "    \"\"\"\n",
    "    Compute the likelihood such as:\n",
    "        L=||weights*(img-obj⨂psf)||²\n",
    "    where `weights` is the inverse of the noise variance.\n",
    "    \"\"\"\n",
    "    obj_tf = fft(obj)\n",
    "    otf = fft(psf)\n",
    "    conv = ifft_real(obj_tf*otf)\n",
    "    fun = np.sum(weights*(image-conv)**2.0) / 2.0\n",
    "    grad = -fft(weights*(image-conv)) * np.conjugate(otf)\n",
    "    grad = ifft_real(grad)\n",
    "    return fun, grad\n",
    "\n",
    "def regularization_quadratic(obj):\n",
    "    \"\"\"\n",
    "    Compute a regularization term of the form:\n",
    "        R=||𝛁x||²+||𝛁y||²\n",
    "    \"\"\"\n",
    "    dx = obj - np.roll(obj,1,axis=0)\n",
    "    dy = obj - np.roll(obj,1,axis=1)\n",
    "    fun = np.sum(dx**2+dy**2)\n",
    "    grad = dx - np.roll(dx,-1,axis=0) + dy - np.roll(dy,-1,axis=1)\n",
    "    return fun, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPcriterion:\n",
    "    def __init__(self, image, psf, photon_noise=False):\n",
    "        self.image = image\n",
    "        self.psf = psf\n",
    "\n",
    "        image_smooth = gaussian_filter(image, 1)\n",
    "        ron_estim = estimate_ron(image, psf, photon_noise=photon_noise)\n",
    "        self.weights = 1/(image_smooth*photon_noise+ron_estim**2)\n",
    "        \n",
    "        self.norma = regularization_quadratic(image_smooth)[0]/image.size\n",
    "        self.norma *= 200 # tune hyper-parameter (empirical)\n",
    "        \n",
    "    def __call__(self, obj_flat):\n",
    "        obj = np.reshape(obj_flat, self.otf.shape)\n",
    "        \n",
    "        # Task - likelihood function\n",
    "\n",
    "        # Task - L2-regulaization function\n",
    "        \n",
    "        # Task: Code your own function for the map criterion \n",
    "        \n",
    "        # Task: Code teh associated gradient function \n",
    "\n",
    "        return map_fun, map_grad.flatten() # exmaple "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are dealing with images with Gaussian noise, the input of the class would be `MAPcriterion(image, psf)`, else: `MAPcriterion(image, psf, photon_noise)`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_criterion = MAPcriterion(image, psf_deconv, photon_noise=photon_noise)\n",
    "\n",
    "obj_guess = (image*(image>0)).flatten()\n",
    "bounds = ((0,None),)*len(obj_guess) # projection on the positive subspace\n",
    "\n",
    "# If you want to find out more about this function fmin_l_bfgs_b: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html\n",
    "solution = fmin_l_bfgs_b(map_criterion, obj_guess, bounds=bounds, factr=10, pgtol=1e-8, iprint=1) \n",
    "\n",
    "print(solution[2]['task'])\n",
    "deconv_map = solution[0].reshape(*psf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT RESULTS\n",
    "rms_image = 100*np.std(vesta-image)*nx**2/flux\n",
    "rms_wiener = 100*np.std(vesta-deconv_wiener)*nx**2/flux\n",
    "rms_map = 100*np.std(vesta-deconv_map)*nx**2/flux\n",
    "\n",
    "print('RMS ERROR')\n",
    "print('Image  : %5.1f'%rms_image)\n",
    "print('Wiener : %5.1f'%rms_wiener)\n",
    "print('MAP    : %5.1f'%rms_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "1. What are the differences between MAP deconvolution and wiener filtering? \n",
    "    - What do you observe? \n",
    "\n",
    "2. What will happen to the deconvolved image when you change the hyperparameter for MAP deconvolution? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circavg(tab):\n",
    "    \"\"\"\n",
    "    Compute the circular average of a given array.\n",
    "    \"\"\"\n",
    "    nx,ny = np.shape(tab)\n",
    "    cx = (nx-1)/2\n",
    "    cy = (ny-1)/2\n",
    "    xx, yy = np.ogrid[0:nx, 0:ny]\n",
    "    rr = np.sqrt((xx-cx)**2 + (yy-cy)**2)\n",
    "    avg = np.zeros(int(rr.max()), dtype=tab.dtype)\n",
    "    for i in range(int(rr.max())):\n",
    "        index = np.where((rr >= i) * (rr < (i + 1)))\n",
    "        avg[i] = tab[index[0], index[1]].sum() / index[0].size\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2, figsize=(15,5))\n",
    "plt.clf()\n",
    "plt.subplot(121)\n",
    "plt.title('Wiener deconvolution')\n",
    "plt.imshow(deconv_wiener, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.title('MAP deconvolution')\n",
    "plt.imshow(deconv_map, cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure(3, figsize=(15,6))\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Wiener')\n",
    "\n",
    "plt.loglog(circavg(np.abs(vesta_tf)**2), label='object')\n",
    "plt.loglog(circavg(np.abs(image_tf)**2), label='image')\n",
    "plt.loglog(circavg(np.abs(deconv_wiener_tf)**2), lw=3, ls=':', c='k', label='deconv')\n",
    "\n",
    "plt.loglog(circavg(psd_obj), c='C0', lw=3, ls=':', label='PSD model')\n",
    "plt.loglog(circavg(psd_noise*np.ones((nx,nx))), c='C3', lw=3, ls=':', label='noise estim')\n",
    "\n",
    "plt.xlabel('Frequency')\n",
    "plt.legend()\n",
    "plt.ylim(1e5, 2*flux**2)\n",
    "plt.xlim(right=nx//2)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('MAP')\n",
    "\n",
    "plt.loglog(circavg(np.abs(vesta_tf)**2), label='object')\n",
    "plt.loglog(circavg(np.abs(image_tf)**2), label='image')\n",
    "plt.loglog(circavg(np.abs(fft(deconv_map))**2), lw=3, ls=':', c='k', label='deconv')\n",
    "\n",
    "plt.xlabel('Frequency')\n",
    "plt.legend()\n",
    "plt.ylim(1e5, 2*flux**2)\n",
    "plt.xlim(right=nx//2)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(4)\n",
    "plt.clf()\n",
    "plt.plot(np.mean(vesta[nx//2-1:nx//2+2,:], axis=0), lw=2, label='Vesta')\n",
    "plt.plot(image[nx//2,:], lw=2, label='image')\n",
    "plt.plot(deconv_wiener[nx//2,:], lw=2, label='Wiener')\n",
    "plt.plot(deconv_map[nx//2,:], lw=2, label='MAP')\n",
    "plt.legend()\n",
    "plt.xlim(0,nx-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks After Running This Tutorial:\n",
    "\n",
    "If you still have some time and would like to explore more about deconvolution, you can use this notebook to investigate the following tasks by adjusting some inputs:\n",
    "\n",
    "1. **Impact of S/N on Deconvolution**:\n",
    "   - How does the signal-to-noise ratio (S/N) affect the deconvolution result?\n",
    "   Try reducing the flux to lower the S/N and observe how the result changes.\n",
    "   \n",
    "2. **Impact of PSF Accuracy on Deconvolution**:\n",
    "   - How does the accuracy of the Point Spread Function (PSF) influence the deconvolution result?\n",
    "   Several PSFs are provided in the folder. Try using a different PSF than the one used to create the image and compare the results (`psf_low_sr.fits, psf_diff.fits`)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
